{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AirBnB is a marketplace for short term rentals that allows you to list part or all of your living space for others to rent. You can rent everything from a room in an apartment to your entire house on AirBnB. Because most of the listings are on a short-term basis, AirBnB has grown to become a popular alternative to hotels. The company itself has grown from it's founding in 2008 to a 30 billion dollar valuation in 2016 and is currently worth more than any hotel chain in the world.\n",
    "\n",
    "One challenge that hosts looking to rent their living space face is determining the optimal nightly rent price. In many areas, renters are presented with a good selection of listings and can filter on criteria like price, number of bedrooms, room type and more. Since AirBnB is a marketplace, the amount a host can charge on a nightly basis is closely linked to the dynamics of the marketplace.\n",
    "\n",
    "As a host, if we try to charge above market price for a living space we'd like to rent, then renters will select the more affordable alternative living spaces that are similar to our living spacematch our living space's amenities. If we set our nightly rent price too low, we'll miss out on potential revenue.\n",
    "\n",
    "One strategy we could use is to:\n",
    "\n",
    "-find a few listings that are similar to ours,\n",
    "-average the listed price for the ones most similar to ours,\n",
    "-set our listing price to this calculated average price.\n",
    "\n",
    "The process of discovering patterns in existing data to make a prediction is called machine learning. In our case, we want to use data on local listings to predict the optimal price for us to set. I will explore a specific machine learning technique called k-nearest neighbors, which mirrors the strategy we just described. Before we dive further into machine learning and k-nearest neighbors, let's get familiar with the dataset we'll be working with.\n",
    "\n",
    "In this project, I'll be working with Airbnbsdataset from October 3, 2015 on the listings from Washington, D.C., the capital of the United States. \n",
    "\n",
    "To make the dataset less cumbersome to work with, we've removed many of the columns in the original dataset and renamed the file to dc_airbnb.csv. Here are the columns we kept:\n",
    "\n",
    "host_response_rate: the response rate of the host\n",
    "host_acceptance_rate: number of requests to the host that convert to rentals\n",
    "host_listings_count: number of other listings the host has\n",
    "latitude: latitude dimension of the geographic coordinates\n",
    "longitude: longitude part of the coordinates\n",
    "city: the city the living space resides\n",
    "zipcode: the zip code the living space resides\n",
    "state: the state the living space resides\n",
    "accommodates: the number of guests the rental can accommodate\n",
    "room_type: the type of living space (Private room, Shared room or Entire home/apt\n",
    "bedrooms: number of bedrooms included in the rental\n",
    "bathrooms: number of bathrooms included in the rental\n",
    "beds: number of beds included in the rental\n",
    "price: nightly price for the rental\n",
    "cleaning_fee: additional fee used for cleaning the living space after the guest leaves\n",
    "security_deposit: refundable security deposit, in case of damages\n",
    "minimum_nights: minimum number of nights a guest can stay for the rental\n",
    "maximum_nights: maximum number of nights a guest can stay for the rental\n",
    "number_of_reviews: number of reviews that previous guests have left\n",
    "Let's read the dataset into Pandas and become more familiar with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7087327</td>\n",
       "      <td>https://www.airbnb.com/rooms/7087327</td>\n",
       "      <td>20151002231825</td>\n",
       "      <td>2015-10-03</td>\n",
       "      <td>Historic DC Condo-Walk to Capitol!</td>\n",
       "      <td>Professional pictures coming soon! Welcome to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Professional pictures coming soon! Welcome to ...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISTRICT OF COLUMBIA, WASHINGTON</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975833</td>\n",
       "      <td>https://www.airbnb.com/rooms/975833</td>\n",
       "      <td>20151002231825</td>\n",
       "      <td>2015-10-03</td>\n",
       "      <td>Spacious Capitol Hill Townhouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beautifully renovated Capitol Hill townhouse. ...</td>\n",
       "      <td>Beautifully renovated Capitol Hill townhouse. ...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISTRICT OF COLUMBIA, WASHINGTON</td>\n",
       "      <td>f</td>\n",
       "      <td>strict</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8249488</td>\n",
       "      <td>https://www.airbnb.com/rooms/8249488</td>\n",
       "      <td>20151002231825</td>\n",
       "      <td>2015-10-03</td>\n",
       "      <td>Spacious/private room for single</td>\n",
       "      <td>This is an ideal room for a single traveler th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is an ideal room for a single traveler th...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8409022</td>\n",
       "      <td>https://www.airbnb.com/rooms/8409022</td>\n",
       "      <td>20151002231825</td>\n",
       "      <td>2015-10-03</td>\n",
       "      <td>A wonderful bedroom with library</td>\n",
       "      <td>Prime location right on the Potomac River in W...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prime location right on the Potomac River in W...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISTRICT OF COLUMBIA, WASHINGTON</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8411173</td>\n",
       "      <td>https://www.airbnb.com/rooms/8411173</td>\n",
       "      <td>20151002231825</td>\n",
       "      <td>2015-10-03</td>\n",
       "      <td>Downtown Silver Spring</td>\n",
       "      <td>Hi travellers! I live in this peaceful spot, b...</td>\n",
       "      <td>This is a 750 sq ft 1 bedroom 1 bathroom.  Whi...</td>\n",
       "      <td>Hi travellers! I live in this peaceful spot, b...</td>\n",
       "      <td>none</td>\n",
       "      <td>Silver Spring is booming.  You can walk to a n...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                           listing_url       scrape_id last_scraped  \\\n",
       "0  7087327  https://www.airbnb.com/rooms/7087327  20151002231825   2015-10-03   \n",
       "1   975833   https://www.airbnb.com/rooms/975833  20151002231825   2015-10-03   \n",
       "2  8249488  https://www.airbnb.com/rooms/8249488  20151002231825   2015-10-03   \n",
       "3  8409022  https://www.airbnb.com/rooms/8409022  20151002231825   2015-10-03   \n",
       "4  8411173  https://www.airbnb.com/rooms/8411173  20151002231825   2015-10-03   \n",
       "\n",
       "                                 name  \\\n",
       "0  Historic DC Condo-Walk to Capitol!   \n",
       "1     Spacious Capitol Hill Townhouse   \n",
       "2    Spacious/private room for single   \n",
       "3    A wonderful bedroom with library   \n",
       "4              Downtown Silver Spring   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Professional pictures coming soon! Welcome to ...   \n",
       "1                                                NaN   \n",
       "2  This is an ideal room for a single traveler th...   \n",
       "3  Prime location right on the Potomac River in W...   \n",
       "4  Hi travellers! I live in this peaceful spot, b...   \n",
       "\n",
       "                                               space  \\\n",
       "0                                                NaN   \n",
       "1  Beautifully renovated Capitol Hill townhouse. ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  This is a 750 sq ft 1 bedroom 1 bathroom.  Whi...   \n",
       "\n",
       "                                         description experiences_offered  \\\n",
       "0  Professional pictures coming soon! Welcome to ...                none   \n",
       "1  Beautifully renovated Capitol Hill townhouse. ...                none   \n",
       "2  This is an ideal room for a single traveler th...                none   \n",
       "3  Prime location right on the Potomac River in W...                none   \n",
       "4  Hi travellers! I live in this peaceful spot, b...                none   \n",
       "\n",
       "                               neighborhood_overview        ...         \\\n",
       "0                                                NaN        ...          \n",
       "1                                                NaN        ...          \n",
       "2                                                NaN        ...          \n",
       "3                                                NaN        ...          \n",
       "4  Silver Spring is booming.  You can walk to a n...        ...          \n",
       "\n",
       "  review_scores_value requires_license license  \\\n",
       "0                 NaN                f     NaN   \n",
       "1                 9.0                f     NaN   \n",
       "2                 NaN                f     NaN   \n",
       "3                 NaN                f     NaN   \n",
       "4                 NaN                f     NaN   \n",
       "\n",
       "                 jurisdiction_names instant_bookable cancellation_policy  \\\n",
       "0  DISTRICT OF COLUMBIA, WASHINGTON                f            flexible   \n",
       "1  DISTRICT OF COLUMBIA, WASHINGTON                f              strict   \n",
       "2                               NaN                f            flexible   \n",
       "3  DISTRICT OF COLUMBIA, WASHINGTON                f            flexible   \n",
       "4                               NaN                f            flexible   \n",
       "\n",
       "   require_guest_profile_picture require_guest_phone_verification  \\\n",
       "0                              f                                f   \n",
       "1                              f                                f   \n",
       "2                              f                                f   \n",
       "3                              f                                f   \n",
       "4                              f                                f   \n",
       "\n",
       "  calculated_host_listings_count reviews_per_month  \n",
       "0                             18               NaN  \n",
       "1                              1              2.11  \n",
       "2                              1              1.00  \n",
       "3                              1               NaN  \n",
       "4                              1               NaN  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dc_listings = pd.read_csv(\"C:/Users/Jennifer/Documents/Python/Data/dc_airbnb.csv\")\n",
    "dc_listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy we will use is find attributes in the data that related well to a listings price. Then we will group a number of listings with similar attributes and then calculate the average nightly price of these listings and set the average price as the price of our listing.\n",
    "\n",
    "We will  define what metrics we are going to use. And then we will implement k-nearest algorithm and use it to suggest a price for a new unpriced listing.\n",
    "\n",
    "First off let's randomize the order of the listings so that we aren't biasing the results to the original order. Additionally lets do some cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3723 entries, 574 to 1061\n",
      "Data columns (total 19 columns):\n",
      "host_response_rate      3289 non-null object\n",
      "host_acceptance_rate    3109 non-null object\n",
      "host_listings_count     3723 non-null int64\n",
      "accommodates            3723 non-null int64\n",
      "room_type               3723 non-null object\n",
      "bedrooms                3702 non-null float64\n",
      "bathrooms               3696 non-null float64\n",
      "beds                    3712 non-null float64\n",
      "price                   3723 non-null float64\n",
      "cleaning_fee            2335 non-null object\n",
      "security_deposit        1426 non-null object\n",
      "minimum_nights          3723 non-null int64\n",
      "maximum_nights          3723 non-null int64\n",
      "number_of_reviews       3723 non-null int64\n",
      "latitude                3723 non-null float64\n",
      "longitude               3723 non-null float64\n",
      "city                    3723 non-null object\n",
      "zipcode                 3714 non-null object\n",
      "state                   3723 non-null object\n",
      "dtypes: float64(6), int64(5), object(8)\n",
      "memory usage: 465.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "columns_to_keep = ['host_response_rate', 'host_acceptance_rate', 'host_listings_count',\n",
    "       'accommodates', 'room_type', 'bedrooms', 'bathrooms', 'beds', 'price',\n",
    "       'cleaning_fee', 'security_deposit', 'minimum_nights', 'maximum_nights',\n",
    "       'number_of_reviews', 'latitude', 'longitude', 'city', 'zipcode',\n",
    "       'state']\n",
    "dc_listings = pd.DataFrame(dc_listings, columns=columns_to_keep)\n",
    "\n",
    "print(dc_listings.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the remaining columns, 3 columns have a few missing values (less than 1% of the total number of rows):\n",
    "\n",
    "bedrooms\n",
    "bathrooms\n",
    "beds\n",
    "\n",
    "Since the number of rows containing missing values for one of these 3 columns is low, we can select and remove those rows without losing much information. There are also 2 columns have a large number of missing values:\n",
    "\n",
    "cleaning_fee - 37.3% of the rows\n",
    "security_deposit - 61.7% of the rows\n",
    "and we can't handle these easily. We can't just remove the rows containing missing values for these 2 columns because we'd miss out on the majority of the observations in the dataset. Instead, let's remove these 2 columns entirely from consideration.\n",
    "\n",
    "We can also go ahead and remove columns that are not numeric in nature and therefore will not be used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates         0\n",
      "bedrooms             0\n",
      "bathrooms            0\n",
      "beds                 0\n",
      "price                0\n",
      "minimum_nights       0\n",
      "maximum_nights       0\n",
      "number_of_reviews    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['room_type', 'city', 'state', 'latitude', 'longitude', 'zipcode', 'host_response_rate', 'host_acceptance_rate', 'host_listings_count']\n",
    "dc_listings = dc_listings.drop(drop_columns, axis=1)\n",
    "dc_listings = dc_listings.drop(['cleaning_fee', 'security_deposit'], axis=1)\n",
    "dc_listings = dc_listings.dropna(axis=0)\n",
    "print(dc_listings.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that while the accommodates, bedrooms, bathrooms, beds, and minimum_nights columns hover between 0 and 12 (at least in the first few rows), the values in the maximum_nights and number_of_reviews columns span much larger ranges. For example, the maximum_nights column has values as low as 4 and high as 1825, in the first few rows itself. If we use these 2 columns as part of a k-nearest neighbors model, these attributes could end up having an outsized effect on the distance calculations because of the largeness of the values.\n",
    "\n",
    "For example, 2 living spaces could be identical across every attribute but be vastly different just on the maximum_nights column. If one listing had a maximum_nights value of 1825 and the other a maximum_nights value of 4, because of the way Euclidean distance is calculated, these listings would be considered very far apart because of the outsized effect the largeness of the values had on the overall Euclidean distance. To prevent any single column from having too much of an impact on the distance, we can normalize all of the columns to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "Normalizing the values in each columns to the standard normal distribution (mean of 0, standard deviation of 1) preserves the distribution of the values in each column while aligning the scales. To normalize the values in a column to the standard normal distribution, you need to:\n",
    "\n",
    "from each value, subtract the mean of the column\n",
    "divide each value by the standard deviation of the column\n",
    "Here's the mathematical formula describing the transformation that needs to be applied for all values in a column:\n",
    "\n",
    "x=x−μσ.\n",
    "\n",
    "where x is a value in a specific column, mu is the mean of all the values in the column, and sigma is the standard deviation of all the values in the column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      accommodates  bedrooms  bathrooms      beds  price  minimum_nights  \\\n",
      "574      -0.596544 -0.249467  -0.439151 -0.546858  125.0       -0.341375   \n",
      "1593     -0.596544 -0.249467   0.412923 -0.546858   85.0       -0.341375   \n",
      "3091     -1.095499 -0.249467  -1.291226 -0.546858   50.0       -0.341375   \n",
      "\n",
      "      maximum_nights  number_of_reviews  \n",
      "574        -0.016604           4.579650  \n",
      "1593       -0.016603           1.159275  \n",
      "3091       -0.016573          -0.482505  \n"
     ]
    }
   ],
   "source": [
    "normalized_listings = (dc_listings - dc_listings.mean())/(dc_listings.std())\n",
    "normalized_listings['price'] = dc_listings['price']\n",
    "print(normalized_listings.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducin Sckit-Learn\n",
    "In this section of code, I will use the scikit-learn library, which is the most popular machine learning in Python. Scikit-learn contains functions for all of the major machine learning algorithms and a simple, unified workflow. \n",
    "\n",
    "The scikit-learn workflow consists of 4 main steps:\n",
    "\n",
    "instantiate the specific machine learning model you want to use\n",
    "fit the model to the training data\n",
    "use the model to make predictions\n",
    "evaluate the accuracy of the predictions\n",
    "\n",
    "Now, we can fit the model to the data using the fit method. For all models, the fit method takes in 2 required parameters:\n",
    "\n",
    "matrix-like object, containing the feature columns we want to use from the training set.\n",
    "list-like object, containing correct target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "train_columns = ['accommodates', 'bathrooms']\n",
    "\n",
    "# Instantiate ML model.\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "\n",
    "# Fit model to data.\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "\n",
    "# Use model to make predictions.\n",
    "predictions = knn.predict(test_df[train_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate MSE and RMSE\n",
    "Inorder to see how our model performed we need to see how far our predictions are from the real results. We look at the mean squared errors of our prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15184.425165\n",
      "123.225099574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_columns = ['accommodates', 'bathrooms']\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "predictions = knn.predict(test_df[train_columns])\n",
    "two_features_mse = mean_squared_error(test_df['price'],predictions)\n",
    "two_features_rmse = np.sqrt(two_features_mse)\n",
    "print(two_features_mse)\n",
    "print(two_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using more features\n",
    "In the previous example we tried to fit a model with two variables. Now let's train a model with the following four features.\n",
    "accommodates\n",
    "bedrooms\n",
    "bathrooms\n",
    "number_of_reviews\n",
    "\n",
    "I noticed that the mse decreased, showing us that we can get a better prediction with more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14044.0656655\n",
      "118.507660788\n"
     ]
    }
   ],
   "source": [
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "knn.fit(train_df[features], train_df['price'])\n",
    "four_predictions = knn.predict(test_df[features])\n",
    "four_mse = mean_squared_error(test_df['price'], four_predictions)\n",
    "four_rmse = four_mse ** (1/2)\n",
    "print(four_mse)\n",
    "print(four_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "When we vary the features that are used in the model, we're affecting the data that the model uses. On the other hand, varying the k value affects the behavior of the model independently of the actual data that's used when making predictions. In other words, we're impacting how the model performs without trying to change the data that's used.\n",
    "\n",
    "Values that affect the behavior and performance of a model that are unrelated to the data that's used are referred to as hyperparameters. The process of finding the optimal hyperparameter value is known as hyperparameter optimization. A simple but common hyperparameter optimization technique is known as grid search, which involves:\n",
    "\n",
    "selecting a subset of the possible hyperparameter values,\n",
    "training a model using each of these hyperparameter values,\n",
    "evaluating each model's performance,\n",
    "selecting the hyperparameter value that resulted in the lowest error value.\n",
    "\n",
    "Grid search essentially boils down to evaluating the model performance at different k values and selecting the k value that resulted in the lowest error. While grid search can take a long time when working with large datasets, the data we're working with in this mission is small and this process is relatively quick.\n",
    "\n",
    "Let's confirm that grid search will work quickly for the dataset we're working with by first observing how the model performance changes as we increase the k value from 1 to 5. If you recall, we set 5 as the k value for the last 2 missions. Let's use the features from the last mission that resulted in the best model accuracy:\n",
    "\n",
    "As we increased the k value from 1 to 5, the MSE value fell from approximately 25919 to approximately 14044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25919.303754266213, 14860.488054607509, 14619.65971432183, 16114.810864618885, 14044.065665529011]\n"
     ]
    }
   ],
   "source": [
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [1, 2, 3, 4, 5]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "print(mse_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying features and hyperparameter\n",
    "Since varying the k value decreased the MSE value for this model, you may be wondering if repeating the grid search process for one of the models from the last mission that performed poorly when we fixed k to 5 would result in a lower MSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23377.956769055745, 14919.195392491467, 15016.039059537354, 15471.579778156996, 15392.625392491465, 15476.989318670207, 15007.347217385251, 15098.53283205347, 15111.675037570752, 14895.770284414109, 14829.184149907387, 14814.059450448744, 14844.193334275771, 14979.669278632955, 14930.406380988499, 15085.460013154152, 15120.421665072374, 15289.255790109413, 15253.693806547983, 15249.665472127419]\n"
     ]
    }
   ],
   "source": [
    "hyper_params = [x for x in range(1,21)]\n",
    "mse_values = list()\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "print(mse_values)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practing the workflow\n",
    "Lets now process the whole workflow in one step. That is I will select relevant features to predict the price of a listing. use grid search to find the optimal parameter value for the selected features and then evaluate the model's accuracy and repeat the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 15184.425164960181}\n",
      "{5: 13281.215108077358}\n"
     ]
    }
   ],
   "source": [
    "two_features = ['accommodates', 'bathrooms']\n",
    "three_features = ['accommodates', 'bathrooms', 'bedrooms']\n",
    "hyper_params = [x for x in range(1,21)]\n",
    "# Append the first model's MSE values to this list.\n",
    "two_mse_values = list()\n",
    "# Append the second model's MSE values to this list.\n",
    "three_mse_values = list()\n",
    "two_hyp_mse = dict()\n",
    "three_hyp_mse = dict()\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[two_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[two_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    two_mse_values.append(mse)\n",
    "\n",
    "two_lowest_mse = two_mse_values[0]\n",
    "two_lowest_k = 1\n",
    "\n",
    "for k,mse in enumerate(two_mse_values):\n",
    "    if mse < two_lowest_mse:\n",
    "        two_lowest_mse = mse\n",
    "        two_lowest_k = k + 1\n",
    "    \n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[three_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[three_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    three_mse_values.append(mse)\n",
    "    \n",
    "three_lowest_mse = three_mse_values[0]\n",
    "three_lowest_k = 1\n",
    "\n",
    "for k,mse in enumerate(three_mse_values):\n",
    "    if mse < three_lowest_mse:\n",
    "        three_lowest_mse = mse\n",
    "        three_lowest_k = k + 1\n",
    "\n",
    "two_hyp_mse[two_lowest_k] = two_lowest_mse\n",
    "three_hyp_mse[three_lowest_k] = three_lowest_mse\n",
    "\n",
    "print(two_hyp_mse)\n",
    "print(three_hyp_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion - Part 1\n",
    "The first model, which used the accommodates and bathrooms columns, was able to achieve an MSE value of approximately 15184. The second model, which added the bedrooms column, was able to achieve an MSE value of approximately 13281, which is even lower than the lowest MSE value we achieved using the best model from the last mission (which used the accommodates, bedrooms, bathrooms, and number_of_reviews columns). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "In the previous cells, we trained a model and tested it on half the data set. I will take this step further and focus on the holdout validation technique which involves:\n",
    "\n",
    "- Splitting the dataset into partitions (training and test)\n",
    "- Training the model on the training set\n",
    "- Using the trained modedl to predict labels on the test set\n",
    "- Computing an error metric to understand the model's effectiveness\n",
    "- Switching the training and test sets and repeat\n",
    "- Average the errors\n",
    "\n",
    "Now that we've split our data set into 2 dataframes, let's:\n",
    "\n",
    "- Train a k-nearest neighbors model on the first half,\n",
    "- Test this model on the second half,\n",
    "- Train a k-nearest neighbors model on the second half,\n",
    "- Test this model on the first half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jennifer\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.945585934 119.010039833 148.477812884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jennifer\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "split_one = dc_listings.iloc[0:1862]\n",
    "split_two = dc_listings.iloc[1862:]\n",
    "train_one = split_one\n",
    "test_one = split_two\n",
    "train_two = split_two\n",
    "test_two = split_one\n",
    "train_one = split_one\n",
    "test_one = split_two\n",
    "train_two = split_two\n",
    "test_two = split_one\n",
    "# First half\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(train_one[[\"accommodates\"]], train_one[\"price\"])\n",
    "test_one[\"predicted_price\"] = model.predict(test_one[[\"accommodates\"]])\n",
    "iteration_one_rmse = mean_squared_error(test_one[\"price\"], test_one[\"predicted_price\"])**(1/2)\n",
    "\n",
    "# Second half\n",
    "model.fit(train_two[[\"accommodates\"]], train_two[\"price\"])\n",
    "test_two[\"predicted_price\"] = model.predict(test_two[[\"accommodates\"]])\n",
    "iteration_two_rmse = mean_squared_error(test_two[\"price\"], test_two[\"predicted_price\"])**(1/2)\n",
    "\n",
    "avg_rmse = np.mean([iteration_two_rmse, iteration_one_rmse])\n",
    "\n",
    "print(iteration_one_rmse, iteration_two_rmse, avg_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Validation\n",
    "If we average the two RMSE values from the last step, we get an RMSE value of approximately 128.96. Holdout validation is actually a specific example of a larger class of validation techniques called k-fold cross-validation. While holdout validation is better than train/test validation because the model isn't repeatedly biased towards a specific subset of the data, both models that are trained only use half the available data. K-fold cross validation, on the other hand, takes advantage of a larger proportion of the data during training while still rotating through different subsets of the data to avoid the issues of train/test validation. Here is how K-Fold Validation works:\n",
    "\n",
    "- splitting the full dataset into k equal length partitions,\n",
    "- selecting k-1 partitions as the training set and\n",
    "- selecting the remaining partition as the test set\n",
    "- training the model on the training set,\n",
    "- using the trained model to predict labels on the test fold,\n",
    "- computing the test fold's error metric,\n",
    "- repeating all of the above steps k-1 times, until each partition has been used as the test set for an iteration,\n",
    "- calculating the mean of the k error values.\n",
    "\n",
    "Let's start by manually partitioning the data set into 5 folds. Instead of splitting into 5 dataframes, let's add a column that specifies which fold the row belongs to. This way, we can easily select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>4</td>\n",
       "      <td>730</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1825</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>92</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>3</td>\n",
       "      <td>730</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>14</td>\n",
       "      <td>180</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>135</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3562</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>5</td>\n",
       "      <td>730</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>206</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3671 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accommodates  bedrooms  bathrooms  beds  price  minimum_nights  \\\n",
       "574              2       1.0        1.0   1.0  125.0               1   \n",
       "1593             2       1.0        1.5   1.0   85.0               1   \n",
       "3091             1       1.0        0.5   1.0   50.0               1   \n",
       "420              2       1.0        1.0   1.0  209.0               4   \n",
       "808             12       5.0        2.0   5.0  215.0               2   \n",
       "3492             8       4.0        2.5   5.0  350.0               4   \n",
       "364              3       0.0        1.0   2.0  115.0               2   \n",
       "1412             2       1.0        1.0   1.0  110.0               2   \n",
       "3219             3       0.0        1.0   1.0   99.0               2   \n",
       "756              2       1.0        1.0   1.0   49.0               1   \n",
       "3089             4       1.0        1.0   3.0  100.0               2   \n",
       "1724             8       3.0        2.0   4.0  395.0               3   \n",
       "3358             2       0.0        1.0   1.0   70.0               1   \n",
       "1131             2       0.0        1.0   1.0   99.0               1   \n",
       "169              1       1.0        1.0   1.0   55.0               1   \n",
       "968              2       1.0        1.0   1.0   74.0               1   \n",
       "2430             2       1.0        1.0   1.0   80.0               4   \n",
       "2418             1       1.0        1.0   1.0   55.0               1   \n",
       "1555             2       1.0        1.0   1.0   42.0               1   \n",
       "3045             5       1.0        1.0   1.0  120.0               2   \n",
       "102              4       2.0        2.0   2.0  299.0               3   \n",
       "1992             4       1.0        1.0   2.0  100.0               1   \n",
       "99               4       2.0        2.0   3.0  180.0               7   \n",
       "2914             5       2.0        2.0   2.0  258.0               3   \n",
       "1729             3       1.0        1.0   2.0   91.0               4   \n",
       "1241             1       1.0        1.0   1.0   75.0              14   \n",
       "2169             2       1.0        1.0   1.0   95.0               1   \n",
       "829              2       0.0        1.0   1.0  178.0               1   \n",
       "1396             2       0.0        1.0   1.0  200.0               2   \n",
       "3081             1       1.0        1.0   1.0   31.0               1   \n",
       "...            ...       ...        ...   ...    ...             ...   \n",
       "3049             2       1.0        1.0   1.0  139.0               1   \n",
       "3287             4       1.0        1.0   3.0   68.0               1   \n",
       "2628             2       1.0        1.0   1.0   99.0               1   \n",
       "562             14       5.0        3.0   7.0  599.0               1   \n",
       "2446             4       2.0        2.0   2.0  199.0               1   \n",
       "668              5       1.0        1.0   2.0  120.0               1   \n",
       "3562             4       1.0        2.0   2.0   90.0               1   \n",
       "252              1       1.0        1.0   1.0  135.0               1   \n",
       "2955             2       1.0        1.0   1.0   82.0               1   \n",
       "2516             6       2.0        1.0   5.0  149.0               1   \n",
       "2962             2       1.0        1.0   1.0  180.0               3   \n",
       "357              3       1.0        1.0   1.0  189.0               5   \n",
       "1278             2       1.0        0.0   1.0   85.0               1   \n",
       "1300             2       1.0        1.0   1.0   75.0               1   \n",
       "1202             2       0.0        1.0   1.0   85.0               1   \n",
       "3353             2       1.0        1.0   1.0  150.0               1   \n",
       "3462             4       1.0        1.0   2.0  115.0               3   \n",
       "2556             4       2.0        1.5   2.0  150.0               3   \n",
       "2797             6       2.0        1.0   2.0  165.0               3   \n",
       "3655             2       1.0        1.0   1.0   90.0               1   \n",
       "129              3       1.0        1.0   2.0  246.0               3   \n",
       "144              2       1.0        1.0   1.0  120.0               1   \n",
       "960              2       1.0        1.0   1.0  165.0               1   \n",
       "2895             6       2.0        1.0   3.0  150.0               1   \n",
       "3717             7       3.0        2.0   3.0  285.0               2   \n",
       "2763             1       0.0        1.0   1.0   75.0               4   \n",
       "905              1       0.0        1.0   1.0   95.0               5   \n",
       "1096             2       1.0        0.0   1.0  100.0               1   \n",
       "235              8       2.0        1.0   4.0  194.0               1   \n",
       "1061             6       1.0        2.5   6.0   36.0               2   \n",
       "\n",
       "      maximum_nights  number_of_reviews  fold  \n",
       "574                4                149   1.0  \n",
       "1593              30                 49   1.0  \n",
       "3091            1125                  1   1.0  \n",
       "420              730                  2   1.0  \n",
       "808             1825                 34   1.0  \n",
       "3492            1125                  1   1.0  \n",
       "364             1125                 63   1.0  \n",
       "1412            1125                  5   1.0  \n",
       "3219              14                 45   1.0  \n",
       "756             1125                  3   1.0  \n",
       "3089            1125                  1   1.0  \n",
       "1724            1125                  0   1.0  \n",
       "3358            1125                  2   1.0  \n",
       "1131            1125                  0   1.0  \n",
       "169               14                  1   1.0  \n",
       "968             1125                  2   1.0  \n",
       "2430              10                 19   1.0  \n",
       "2418              60                  7   1.0  \n",
       "1555            1125                 17   1.0  \n",
       "3045            1125                 92   1.0  \n",
       "102              730                  7   1.0  \n",
       "1992            1125                  2   1.0  \n",
       "99                21                 48   1.0  \n",
       "2914            1125                  0   1.0  \n",
       "1729            1125                  0   1.0  \n",
       "1241             180                 12   1.0  \n",
       "2169            1125                 19   1.0  \n",
       "829             1125                  4   1.0  \n",
       "1396              90                  0   1.0  \n",
       "3081               6                  3   1.0  \n",
       "...              ...                ...   ...  \n",
       "3049            1125                 14   5.0  \n",
       "3287            1125                135   5.0  \n",
       "2628              30                 61   5.0  \n",
       "562             1125                  0   5.0  \n",
       "2446              15                  0   5.0  \n",
       "668             1125                  2   5.0  \n",
       "3562            1125                  2   5.0  \n",
       "252             1125                  0   5.0  \n",
       "2955            1125                 25   5.0  \n",
       "2516             365                 32   5.0  \n",
       "2962            1125                  1   5.0  \n",
       "357              730                  0   5.0  \n",
       "1278              60                206   5.0  \n",
       "1300               8                  2   5.0  \n",
       "1202              60                 30   5.0  \n",
       "3353            1125                  0   5.0  \n",
       "3462              60                 63   5.0  \n",
       "2556            1125                  1   5.0  \n",
       "2797              30                  0   5.0  \n",
       "3655            1125                 14   5.0  \n",
       "129             1125                  0   5.0  \n",
       "144             1125                  0   5.0  \n",
       "960               29                 19   5.0  \n",
       "2895            1125                  1   5.0  \n",
       "3717            1125                  8   5.0  \n",
       "2763              20                  1   5.0  \n",
       "905             1125                  0   5.0  \n",
       "1096            1125                 15   5.0  \n",
       "235             1125                  8   5.0  \n",
       "1061              30                  7   5.0  \n",
       "\n",
       "[3671 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings.set_value(dc_listings.index[0:744], \"fold\", 1)\n",
    "dc_listings.set_value(dc_listings.index[744:1488], \"fold\", 2)\n",
    "dc_listings.set_value(dc_listings.index[1488:2232], \"fold\", 3)\n",
    "dc_listings.set_value(dc_listings.index[2232:2976], \"fold\", 4)\n",
    "dc_listings.set_value(dc_listings.index[2976:3723], \"fold\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jennifer\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105.78011099313723, 133.83595459343309, 156.12625198582009, 128.16695869480273, 123.94054225469763]\n",
      "129.569963704\n"
     ]
    }
   ],
   "source": [
    "fold_ids = [1,2,3,4,5]\n",
    "def train_and_validate(df, folds):\n",
    "    fold_rmses = []\n",
    "    for fold in folds:\n",
    "        # Train\n",
    "        model = KNeighborsRegressor()\n",
    "        train = df[df[\"fold\"] != fold]\n",
    "        test = df[df[\"fold\"] == fold]\n",
    "        model.fit(train[[\"accommodates\"]], train[\"price\"])\n",
    "        # Predict\n",
    "        labels = model.predict(test[[\"accommodates\"]])\n",
    "        test[\"predicted_price\"] = labels\n",
    "        mse = mean_squared_error(test[\"price\"], test[\"predicted_price\"])\n",
    "        rmse = mse**(1/2)\n",
    "        fold_rmses.append(rmse)\n",
    "    return(fold_rmses)\n",
    "\n",
    "rmses = train_and_validate(dc_listings, fold_ids)\n",
    "print(rmses)\n",
    "avg_rmse = np.mean(rmses)\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing K-Fold Cross Validation using Scikit Learn\n",
    "While the average RMSE value was approximately 136.78, the RMSE values ranged from 105.06 all the way to 156. This large amount of variability between the RMSE values means that I'm either using a poor model or a poor evaluation criteria (or a bit of both!). Now let's try the above process using Scikit learn's cross validation module while exploring different k-fols and different features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 folds:  avg RMSE:  123.170643757 std RMSE:  4.26893303599\n",
      "5 folds:  avg RMSE:  128.499315921 std RMSE:  16.9789389088\n",
      "7 folds:  avg RMSE:  127.97513377 std RMSE:  20.4954352705\n",
      "9 folds:  avg RMSE:  123.618726694 std RMSE:  24.383915795\n",
      "10 folds:  avg RMSE:  127.147684521 std RMSE:  24.1297108046\n",
      "11 folds:  avg RMSE:  127.61624299 std RMSE:  29.3674088594\n",
      "13 folds:  avg RMSE:  122.748356555 std RMSE:  32.3783522657\n",
      "15 folds:  avg RMSE:  122.757645401 std RMSE:  32.893260161\n",
      "17 folds:  avg RMSE:  123.005053153 std RMSE:  35.4887123794\n",
      "19 folds:  avg RMSE:  122.148212352 std RMSE:  35.1736563994\n",
      "21 folds:  avg RMSE:  121.109422469 std RMSE:  37.1157474467\n",
      "23 folds:  avg RMSE:  124.939858948 std RMSE:  39.2787187113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "num_folds = [3, 5, 7, 9, 10, 11, 13, 15, 17, 19, 21, 23]\n",
    "\n",
    "for fold in num_folds:\n",
    "    kf = KFold(fold, shuffle=True, random_state=1)\n",
    "    model = KNeighborsRegressor()\n",
    "    mses = cross_val_score(model, dc_listings[[\"accommodates\"]], dc_listings[\"price\"], scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "    rmses = [np.sqrt(np.absolute(mse)) for mse in mses]\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    std_rmse = np.std(rmses)\n",
    "    print(str(fold), \"folds: \", \"avg RMSE: \", str(avg_rmse), \"std RMSE: \", str(std_rmse))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion Part 2\n",
    "So far, I have been working under the assumption that a lower RMSE always means that a model is more accurate. This isn't the complete picture, unfortunately. A model has two sources of error, bias and variance.\n",
    "\n",
    "Bias describes error that results in bad assumptions about the learning algorithm. For example, assuming that only one feature, like a car's weight, relates to a car's fuel efficiency will lead you to fit a simple, univariate regression model that will result in high bias. The error rate will be high since a car's fuel efficiency is affected by many other factors besides just its weight.\n",
    "\n",
    "Variance describes error that occurs because of the variability of a model's predicted values. If we were given a dataset with 1000 features on each listing and used every single feature to train an incredibly complicated multivariate regression model, we will have low bias but high variance. In an ideal world, we want low bias and low variance but in reality, there's always a tradeoff.\n",
    "\n",
    "The standard deviation of the RMSE values can be a proxy for a model's variance while the average RMSE is a proxy for a model's bias. Bias and variance are the 2 observable sources of error in a model that we can indirectly control.\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
